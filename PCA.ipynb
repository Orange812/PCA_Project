{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "#ELO评分算法实现\n",
    "\n",
    "def initialize_elo_scores(team_positions_df):\n",
    "    teams = team_positions_df['team_name'].unique().tolist()\n",
    "    team_elo = {team: 1500 for team in teams}\n",
    "    for team in teams:\n",
    "        # 赛季中的排名越高，ELO分数越高\n",
    "        team_data = team_positions_df[team_positions_df['team_name'] == team]\n",
    "        rank = team_data['points_per_game'].rank().iloc[0]\n",
    "        team_elo[team] += (20 * (len(teams) - rank))  # 给高排名的球队加分\n",
    "    return team_elo\n",
    "\n",
    "\n",
    "def update_elo_scores(elo_scores, home_team, away_team, home_score, away_score, K=30):\n",
    "    home_elo = elo_scores[home_team]\n",
    "    away_elo = elo_scores[away_team]\n",
    "\n",
    "    # 计算预期得分\n",
    "    expected_home = 1 / (1 + 10 ** ((away_elo - home_elo) / 400))\n",
    "    expected_away = 1 / (1 + 10 ** ((home_elo - away_elo) / 400))\n",
    "\n",
    "    # 根据比赛结果调整ELO分数\n",
    "    if home_score > away_score:  # 主队胜\n",
    "        elo_scores[home_team] += K * (1 - expected_home)\n",
    "        elo_scores[away_team] += K * (0 - expected_away)\n",
    "    elif home_score < away_score:  # 客队胜\n",
    "        elo_scores[home_team] += K * (0 - expected_home)\n",
    "        elo_scores[away_team] += K * (1 - expected_away)\n",
    "    else:  # 平局\n",
    "        elo_scores[home_team] += K * (0.5 - expected_home)\n",
    "        elo_scores[away_team] += K * (0.5 - expected_away)\n",
    "\n",
    "    return elo_scores\n",
    "\n",
    "\n",
    "\n",
    "# 数据加载与预处理\n",
    "def load_all_league_data(base_path, leagues, seasons):\n",
    "    \"\"\"\n",
    "    读取并合并所有联赛、所有赛季的球队数据和比赛数据，\n",
    "    并使用 PCA 将球队特征降维到二维。\n",
    "    返回以下数据结构\n",
    "      - combined_team_positions: DataFrame，每行代表某球队在某赛季的降维结果\n",
    "      - combined_match_positions: DataFrame，每行代表一场比赛的降维结果\n",
    "    \"\"\"\n",
    "    all_team_positions = []\n",
    "    all_match_positions = []\n",
    "    for country_name, league_name in leagues:\n",
    "        for season in seasons:\n",
    "            print(f\"Loading data for: {country_name} - {league_name} - {season}\")\n",
    "            team_file = os.path.join(base_path, f\"{country_name}-{league_name}-teams-{season}-stats.csv\")\n",
    "            match_file = os.path.join(base_path, f\"{country_name}-{league_name}-matches-{season}-stats.csv\")\n",
    "            if not os.path.exists(team_file) or not os.path.exists(match_file):\n",
    "                print(f\"Warning: Missing files for {country_name} - {league_name} - {season}\")\n",
    "                continue\n",
    "\n",
    "            team_df = pd.read_csv(team_file)\n",
    "            match_df = pd.read_csv(match_file)\n",
    "\n",
    "            # 如果 \"common_name\" 列不存在，尝试使用其他列名\n",
    "            team_names = team_df.get('common_name', team_df.get('team_name', None))\n",
    "            if team_names is None:\n",
    "                print(f\"Error: Neither 'common_name' nor 'team_name' columns found in {team_file}\")\n",
    "                continue\n",
    "\n",
    "            points_per_game = team_df['points_per_game']\n",
    "\n",
    "            # 提取防守数据\n",
    "            defensive_columns = [\n",
    "                'goals_conceded', 'goals_conceded_home', 'goals_conceded_away',\n",
    "                'goals_conceded_per_match', 'goals_conceded_per_match_home', 'goals_conceded_per_match_away',\n",
    "                'clean_sheets', 'clean_sheets_home', 'clean_sheets_away',\n",
    "                'clean_sheet_percentage', 'clean_sheet_percentage_home', 'clean_sheet_percentage_away',\n",
    "                'minutes_per_goal_conceded', 'minutes_per_goal_conceded_home', 'minutes_per_goal_conceded_away',\n",
    "                'goals_conceded_half_time', 'goals_conceded_half_time_home', 'goals_conceded_half_time_away',\n",
    "                'clean_sheet_half_time', 'clean_sheet_half_time_percentage',\n",
    "                'fouls', 'fouls_home', 'fouls_away', 'cards_total', 'cards_total_home', 'cards_total_away',\n",
    "                'xg_against_avg_overall', 'xg_against_avg_home', 'xg_against_avg_away'\n",
    "            ]\n",
    "            team_df = team_df[defensive_columns].fillna(0)\n",
    "\n",
    "            # 标准化防守数据\n",
    "            scaler_defense = StandardScaler()\n",
    "            X_scaled_defense = scaler_defense.fit_transform(team_df)\n",
    "\n",
    "            # 使用PCA进行降维，提取防守的主成分\n",
    "            pca_defense = PCA(n_components=2)  # Ensure we extract both PC1 and PC2\n",
    "            X_pca_defense = pca_defense.fit_transform(X_scaled_defense)\n",
    "\n",
    "            # Check if PCA generated two components\n",
    "            if X_pca_defense.shape[1] < 2:\n",
    "                print(f\"Warning: PCA did not produce two components for {team_file}\")\n",
    "                continue\n",
    "\n",
    "            team_positions = pd.DataFrame({\n",
    "                'team_name': team_names,\n",
    "                'PC1': X_pca_defense[:, 0],  # PC1 is the first principal component\n",
    "                'PC2': X_pca_defense[:, 1],  # PC2 is the second principal component\n",
    "                'points_per_game': points_per_game,\n",
    "                'league': league_name,\n",
    "                'season': season\n",
    "            })\n",
    "            all_team_positions.append(team_positions)\n",
    "\n",
    "            # 处理比赛数据（保持原有处理方法）\n",
    "            irrelevant_cols = ['timestamp', 'date_GMT', 'status', 'attendance', 'referee', 'stadium_name', 'Game Week']\n",
    "            match_df = match_df.drop(columns=irrelevant_cols, errors='ignore')\n",
    "            for col in match_df.columns:\n",
    "                match_df[col] = match_df[col].astype(str).str.replace(',', '.', regex=True)\n",
    "                try:\n",
    "                    match_df[col] = pd.to_numeric(match_df[col])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            numeric_cols = match_df.select_dtypes(include=[np.number]).columns\n",
    "            match_df[numeric_cols] = match_df[numeric_cols].fillna(match_df[numeric_cols].mean())\n",
    "            scaler_match = StandardScaler()\n",
    "            X_scaled_match = scaler_match.fit_transform(match_df[numeric_cols])\n",
    "            pca_match = PCA(n_components=2)\n",
    "            X_pca_match = pca_match.fit_transform(X_scaled_match)\n",
    "            match_positions = pd.DataFrame({\n",
    "                'home_team_name': match_df['home_team_name'],\n",
    "                'away_team_name': match_df['away_team_name'],\n",
    "                'PC1': X_pca_match[:, 0],\n",
    "                'PC2': X_pca_match[:, 1],\n",
    "                'league': league_name,\n",
    "                'season': season\n",
    "            })\n",
    "            all_match_positions.append(match_positions)\n",
    "    combined_team_positions = pd.concat(all_team_positions, ignore_index=True)\n",
    "    combined_match_positions = pd.concat(all_match_positions, ignore_index=True)\n",
    "    return combined_team_positions, combined_match_positions\n",
    "\n",
    "\n",
    "def compute_total_loss(positions, match_home_idx, match_away_idx,\n",
    "                       match_PC1, match_PC2, points_per_game, rank_scale,\n",
    "                       avg_conceded, def_shots, lambda_reg, elo_scores, alpha=2.0):\n",
    "    epsilon = 1e-12\n",
    "    num_matches = tf.shape(match_home_idx)[0]\n",
    "    if num_matches == 0:\n",
    "        return tf.constant(0.0, dtype=tf.float32)\n",
    "\n",
    "    # 确保 elo_scores 是一维张量\n",
    "    elo_scores = tf.convert_to_tensor(elo_scores, dtype=tf.float32)\n",
    "\n",
    "    # 计算比赛损失部分\n",
    "    home_pos = tf.gather(positions, match_home_idx)\n",
    "    away_pos = tf.gather(positions, match_away_idx)\n",
    "    match_points = tf.stack([match_PC1, match_PC2], axis=1)\n",
    "    dist_home = tf.norm(home_pos - match_points, axis=1)\n",
    "    dist_away = tf.norm(away_pos - match_points, axis=1)\n",
    "    all_distances = tf.concat([dist_home, dist_away], axis=0)\n",
    "    min_dist = tf.reduce_min(all_distances)\n",
    "    max_dist = tf.reduce_max(all_distances)\n",
    "    denom = (max_dist - min_dist) + epsilon\n",
    "    dist_home_norm = (dist_home - min_dist) / denom\n",
    "    dist_away_norm = (dist_away - min_dist) / denom\n",
    "\n",
    "    # 更新距离占比：根据ELO差异调整\n",
    "    home_elo = tf.gather(elo_scores, match_home_idx)\n",
    "    away_elo = tf.gather(elo_scores, match_away_idx)\n",
    "    elo_diff = tf.abs(home_elo - away_elo)\n",
    "\n",
    "    # 计算比赛损失并调整重要性\n",
    "    weight = 1.0 / (1.0 + elo_diff * rank_scale)\n",
    "    match_loss = weight * (dist_home_norm + dist_away_norm)\n",
    "    match_loss_mean = tf.reduce_mean(match_loss)\n",
    "\n",
    "    # 防守正则化部分：计算防守主成分与实际防守的差异\n",
    "    defense_target = 1.0 - (avg_conceded / (def_shots + epsilon))\n",
    "    defense_error = tf.square(positions[:, 1] - defense_target)\n",
    "    defense_loss = lambda_reg * tf.reduce_mean(defense_error)\n",
    "\n",
    "    total_loss = match_loss_mean + defense_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Adam优化器训练 \n",
    "def adam_optimize_positions(team_positions_df, match_positions_df, initial_lr=0.007,\n",
    "                            decay_steps=50000, decay_rate=0.80, clipnorm=1.0,\n",
    "                            iterations=50000, verbose_interval=500, random_seed=42,\n",
    "                            lambda_reg=1.0, alpha=2.0):\n",
    "    \"\"\"\n",
    "    在给定的训练比赛数据上，用 Adam 优化器同时更新球队坐标 (positions) 和可学习参数 rank_scale，\n",
    "    使用ELO评分来调整每场比赛的权重。\n",
    "    \"\"\"\n",
    "    # 初始化ELO分数字典\n",
    "    elo_scores_dict = initialize_elo_scores(team_positions_df)\n",
    "    teams = team_positions_df['team_name'].unique().tolist()\n",
    "    # 根据teams列表的顺序生成ELO分数张量\n",
    "    elo_scores = tf.convert_to_tensor([elo_scores_dict[team] for team in teams], dtype=tf.float32)\n",
    "\n",
    "    team_name_to_idx = {t: i for i, t in enumerate(teams)}\n",
    "    num_teams = len(teams)\n",
    "    init_positions = np.zeros((num_teams, 2), dtype=np.float32)\n",
    "    init_points_pg = np.zeros((num_teams,), dtype=np.float32)\n",
    "    init_avg_conceded = np.zeros((num_teams,), dtype=np.float32)\n",
    "    init_def_shots = np.zeros((num_teams,), dtype=np.float32)\n",
    "\n",
    "    for i, tname in enumerate(teams):\n",
    "        row = team_positions_df.loc[team_positions_df['team_name'] == tname].iloc[0]\n",
    "        init_positions[i, 0] = row['PC1']\n",
    "        init_positions[i, 1] = row['PC2']\n",
    "        init_points_pg[i] = row['points_per_game']\n",
    "        init_avg_conceded[i] = row.get(\"avg_goals_conceded\", 0.0)\n",
    "        init_def_shots[i] = row.get(\"avg_shots_on_target_conceded\", 0.0)\n",
    "\n",
    "    match_array = []\n",
    "    for idx, row in match_positions_df.iterrows():\n",
    "        hname = row['home_team_name']\n",
    "        aname = row['away_team_name']\n",
    "        if hname in team_name_to_idx and aname in team_name_to_idx:\n",
    "            match_array.append([team_name_to_idx[hname],\n",
    "                                team_name_to_idx[aname],\n",
    "                                row['PC1'], row['PC2']])\n",
    "    match_array = np.array(match_array, dtype=np.float32)\n",
    "    if len(match_array) == 0:\n",
    "        print(\"Warning: No valid matches found for training!\")\n",
    "        return [], team_positions_df, None\n",
    "    match_home_idx = tf.constant(match_array[:, 0], dtype=tf.int32)\n",
    "    match_away_idx = tf.constant(match_array[:, 1], dtype=tf.int32)\n",
    "    match_PC1 = tf.constant(match_array[:, 2], dtype=tf.float32)\n",
    "    match_PC2 = tf.constant(match_array[:, 3], dtype=tf.float32)\n",
    "    points_per_game = tf.constant(init_points_pg, dtype=tf.float32)\n",
    "    avg_conceded_tf = tf.constant(init_avg_conceded, dtype=tf.float32)\n",
    "    def_shots_tf = tf.constant(init_def_shots, dtype=tf.float32)\n",
    "    tf.random.set_seed(random_seed)\n",
    "    positions = tf.Variable(init_positions, name=\"positions\", dtype=tf.float32)\n",
    "    rank_scale = tf.Variable(8.0, name=\"rank_scale\", dtype=tf.float32)\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=initial_lr,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=decay_rate,\n",
    "        staircase=False\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, clipnorm=clipnorm)\n",
    "    losses = []\n",
    "    best_loss = np.inf\n",
    "    best_positions = None\n",
    "    best_rank_scale = None\n",
    "    for i in range(iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = compute_total_loss(positions, match_home_idx, match_away_idx,\n",
    "                                      match_PC1, match_PC2, points_per_game, rank_scale,\n",
    "                                      avg_conceded_tf, def_shots_tf, lambda_reg, elo_scores, alpha)\n",
    "        grads = tape.gradient(loss, [positions, rank_scale])\n",
    "        optimizer.apply_gradients(zip(grads, [positions, rank_scale]))\n",
    "        loss_val = float(loss.numpy())\n",
    "        losses.append(loss_val)\n",
    "        if loss_val < best_loss:\n",
    "            best_loss = loss_val\n",
    "            best_positions = positions.numpy().copy()\n",
    "            best_rank_scale = float(rank_scale.numpy())\n",
    "        if (i + 1) % verbose_interval == 0:\n",
    "            step = optimizer.iterations.numpy()\n",
    "            current_lr = lr_schedule(step).numpy()\n",
    "            print(\n",
    "                f\"Iteration {i + 1}/{iterations}, Loss = {loss_val:.4f}, LR = {current_lr:.6f}, rank_scale = {rank_scale.numpy():.4f}\")\n",
    "    positions.assign(best_positions)\n",
    "    rank_scale.assign(best_rank_scale)\n",
    "    print(f\"=> Finished training, best_loss={best_loss:.4f}, best rank_scale={best_rank_scale:.4f}\")\n",
    "    final_pos = positions.numpy()\n",
    "    for tname, idx in team_name_to_idx.items():\n",
    "        team_positions_df.loc[team_positions_df['team_name'] == tname, 'PC1'] = final_pos[idx, 0]\n",
    "        team_positions_df.loc[team_positions_df['team_name'] == tname, 'PC2'] = final_pos[idx, 1]\n",
    "    team_positions_df.to_csv(\"trained_team_positions.csv\", index=False)\n",
    "    with open(\"best_rank_scale.txt\", \"w\") as f:\n",
    "        f.write(str(best_rank_scale))\n",
    "    return losses, team_positions_df, best_rank_scale\n",
    "\n",
    "def run_cross_validation(team_positions, match_positions, n_splits=3, test_size=0.2,\n",
    "                         random_state=42, **opt_kwargs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    splits_info = []\n",
    "    matches_df_all = match_positions.copy()\n",
    "    all_indices = matches_df_all.index.values\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        print(f\"\\n===== Split {i + 1}/{n_splits} =====\")\n",
    "        idx_train, idx_test = train_test_split(all_indices, test_size=test_size,\n",
    "                                               random_state=random_state + i)\n",
    "        train_matches_df = matches_df_all.loc[idx_train].copy()\n",
    "        test_matches_df = matches_df_all.loc[idx_test].copy()\n",
    "        \n",
    "        losses, best_positions_df, best_scale_val = adam_optimize_positions(\n",
    "            team_positions.copy(), train_matches_df, **opt_kwargs)\n",
    "        train_losses.append(losses[-1])\n",
    "        \n",
    "        elo_scores_dict = initialize_elo_scores(best_positions_df)\n",
    "        teams_test = best_positions_df['team_name'].unique().tolist()\n",
    "        elo_scores = [elo_scores_dict[team] for team in teams_test]\n",
    "        elo_scores = tf.convert_to_tensor(elo_scores, dtype=tf.float32)\n",
    "\n",
    "        team_name_to_idx_test = {t: j for j, t in enumerate(teams_test)}\n",
    "        final_positions = np.zeros((len(teams_test), 2), dtype=np.float32)\n",
    "        final_points_pg = np.zeros((len(teams_test),), dtype=np.float32)\n",
    "        final_avg_conceded = np.zeros((len(teams_test),), dtype=np.float32)\n",
    "        final_def_shots = np.zeros((len(teams_test),), dtype=np.float32)\n",
    "\n",
    "        for j, tname in enumerate(teams_test):\n",
    "            row = best_positions_df.loc[best_positions_df['team_name'] == tname].iloc[0]\n",
    "            final_positions[j, 0] = row['PC1']\n",
    "            final_positions[j, 1] = row['PC2']\n",
    "            final_points_pg[j] = row['points_per_game']\n",
    "            final_avg_conceded[j] = row.get(\"avg_goals_conceded\", 0.0)\n",
    "            final_def_shots[j] = row.get(\"avg_shots_on_target_conceded\", 0.0)\n",
    "\n",
    "        # 显式转换为TensorFlow张量\n",
    "        positions_tf = tf.constant(final_positions, dtype=tf.float32)\n",
    "        points_pg_tf = tf.constant(final_points_pg, dtype=tf.float32)\n",
    "        avg_conceded_tf_test = tf.constant(final_avg_conceded, dtype=tf.float32)\n",
    "        def_shots_tf_test = tf.constant(final_def_shots, dtype=tf.float32)\n",
    "        rank_scale_tf = tf.constant(best_scale_val, dtype=tf.float32)\n",
    "\n",
    "        # 准备测试数据\n",
    "        test_array = []\n",
    "        for idx, row in test_matches_df.iterrows():\n",
    "            hname = row['home_team_name']\n",
    "            aname = row['away_team_name']\n",
    "            if hname in team_name_to_idx_test and aname in team_name_to_idx_test:\n",
    "                test_array.append([team_name_to_idx_test[hname],\n",
    "                                   team_name_to_idx_test[aname],\n",
    "                                   row['PC1'], row['PC2']])\n",
    "        test_array = np.array(test_array, dtype=np.float32)\n",
    "        if len(test_array) == 0:\n",
    "            print(\"Warning: no valid test matches in this split!\")\n",
    "            test_losses.append(np.nan)\n",
    "            splits_info.append((np.nan, losses[-1]))\n",
    "            continue\n",
    "            \n",
    "        match_home_idx_test = tf.constant(test_array[:, 0], dtype=tf.int32)\n",
    "        match_away_idx_test = tf.constant(test_array[:, 1], dtype=tf.int32)\n",
    "        match_PC1_test = tf.constant(test_array[:, 2], dtype=tf.float32)\n",
    "        match_PC2_test = tf.constant(test_array[:, 3], dtype=tf.float32)\n",
    "\n",
    "        # 计算测试损失\n",
    "        test_loss_val = compute_total_loss(\n",
    "            positions_tf,  # 现在这个变量已正确定义\n",
    "            match_home_idx_test,\n",
    "            match_away_idx_test,\n",
    "            match_PC1_test,\n",
    "            match_PC2_test,\n",
    "            points_pg_tf,\n",
    "            rank_scale_tf,\n",
    "            avg_conceded_tf_test,\n",
    "            def_shots_tf_test,\n",
    "            opt_kwargs.get(\"lambda_reg\", 0.1),\n",
    "            elo_scores,\n",
    "            alpha=2.0\n",
    "        ).numpy()\n",
    "        \n",
    "        test_losses.append(test_loss_val)\n",
    "        splits_info.append((losses[-1], test_loss_val))\n",
    "        print(f\"Split {i + 1}: Train Loss = {losses[-1]:.4f}, Test Loss = {test_loss_val:.4f}\")\n",
    "    \n",
    "    valid_train_losses = [x for x in train_losses if not np.isnan(x)]\n",
    "    valid_test_losses = [x for x in test_losses if not np.isnan(x)]\n",
    "    print(\"\\n===== Cross Validation Summary =====\")\n",
    "    print(f\"Train Losses = {valid_train_losses}\")\n",
    "    print(f\"Test  Losses = {valid_test_losses}\")\n",
    "    if valid_train_losses:\n",
    "        print(f\"Avg Train Loss = {np.mean(valid_train_losses):.4f} +- {np.std(valid_train_losses):.4f}\")\n",
    "    if valid_test_losses:\n",
    "        print(f\"Avg Test  Loss = {np.mean(valid_test_losses):.4f} +- {np.std(valid_test_losses):.4f}\")\n",
    "    return splits_info\n",
    "\n",
    "# 可视化\n",
    "def visualize_team_evolution_by_league_static(team_positions_df, seasons_order):\n",
    "    output_dir = \"/Users/peixuanma/Downloads/Output_Graphs\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    leagues = team_positions_df['league'].unique().tolist()\n",
    "    for league in leagues:\n",
    "        league_df = team_positions_df.loc[team_positions_df['league'] == league].copy()\n",
    "        team_counts = league_df.groupby(\"team_name\")[\"season\"].nunique()\n",
    "        valid_teams = team_counts[team_counts == len(seasons_order)].index.tolist()\n",
    "        if not valid_teams:\n",
    "            print(f\"No team continuously in {league} for all seasons. Using all teams instead.\")\n",
    "            valid_teams = league_df['team_name'].unique().tolist()\n",
    "        valid_df = league_df.loc[league_df[\"team_name\"].isin(valid_teams)].copy()\n",
    "        valid_df.loc[:, \"season\"] = pd.Categorical(valid_df[\"season\"], categories=seasons_order, ordered=True)\n",
    "        valid_df = valid_df.sort_values([\"team_name\", \"season\"])\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.title(f\"{league} - Team Evolution (Offense-Defense)\")\n",
    "        plt.xlabel(\"PC1 (Offense)\")\n",
    "        plt.ylabel(\"PC2 (Defense)\")\n",
    "        plt.grid(True)\n",
    "\n",
    "        teams = valid_df['team_name'].unique().tolist()\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(teams)))\n",
    "        team_colors = dict(zip(teams, colors))\n",
    "\n",
    "        for team in teams:\n",
    "            sub = valid_df.loc[valid_df['team_name'] == team].sort_values(\"season\")\n",
    "            plt.plot(sub['PC1'], sub['PC2'], marker='o', linestyle='-', color=team_colors[team], label=team)\n",
    "            for idx, row in sub.iterrows():\n",
    "                plt.text(row['PC1'], row['PC2'], str(row['season']), fontsize=8, ha='right', va='bottom')\n",
    "\n",
    "        plt.legend(fontsize=8, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        filename = os.path.join(output_dir, f\"{league}_evolution_static.png\")\n",
    "        plt.savefig(filename, dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"Saved static evolution graph for {league} -> {filename}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = '/Users/peixuanma/Downloads/data1'\n",
    "    leagues = [\n",
    "        (\"england\", \"premier-league\"),\n",
    "        (\"germany\", \"bundesliga\"),\n",
    "        (\"spain\", \"la-liga\"),\n",
    "        (\"france\", \"ligue-1\"),\n",
    "        (\"italy\", \"serie-a\"),\n",
    "        (\"netherlands\", \"eredivisie\"),\n",
    "        (\"portugal\", \"ligapro\"),\n",
    "        (\"denmark\", \"superliga\"),\n",
    "        (\"england\", \"championship\"),\n",
    "        (\"belgium\", \"pro-league\")\n",
    "    ]\n",
    "    seasons = [\n",
    "        \"2013-to-2014\", \"2014-to-2015\", \"2015-to-2016\", \"2016-to-2017\",\n",
    "        \"2017-to-2018\", \"2018-to-2019\", \"2020-to-2021\",\n",
    "        \"2021-to-2022\", \"2022-to-2023\", \"2023-to-2024\"\n",
    "    ]\n",
    "\n",
    "    # 第1步：加载数据\n",
    "    all_team_positions, all_match_positions = load_all_league_data(base_path, leagues, seasons)\n",
    "\n",
    "    # 第2步：交叉验证 - 随机拆分80%训练，20%测试\n",
    "    print(\"\\n===== Running Cross Validation =====\")\n",
    "    run_cross_validation(team_positions=all_team_positions, match_positions=all_match_positions,\n",
    "                         n_splits=3, test_size=0.2, random_state=42,\n",
    "                         initial_lr=0.005, decay_steps=100000,\n",
    "                         decay_rate=0.80, clipnorm=1.0, iterations=100000,\n",
    "                         verbose_interval=10000, lambda_reg=1.0, alpha=2.0)\n",
    "    # 第3步：最终模型训练与保存（使用全部数据训练最终模型）\n",
    "    print(\"\\n===== Final Model Training and Saving =====\")\n",
    "    final_losses, final_team_positions, final_rank_scale = adam_optimize_positions(\n",
    "        all_team_positions.copy(), all_match_positions.copy(),\n",
    "        initial_lr=0.005, decay_steps=100000, decay_rate=0.80,\n",
    "        clipnorm=1.0, iterations=100000, verbose_interval=10000, random_seed=42,\n",
    "        lambda_reg=1.0, alpha=2.0\n",
    "    )\n",
    "    if final_losses:  # 确保final_losses不为空\n",
    "        final_team_positions.to_csv(\"trained_team_positions.csv\", index=False)\n",
    "        with open(\"best_rank_scale.txt\", \"w\") as f:\n",
    "            f.write(str(final_rank_scale))\n",
    "        print(f\"Final training loss: {final_losses[-1]:.4f}, best rank_scale: {final_rank_scale:.4f}\")\n",
    "\n",
    "    # 第4步：静态可视化 - 针对每个联赛展示持续出现（未降级）的球队风格变化轨迹（攻防象限图）\n",
    "    print(\"\\n===== Static Visualization of Team Evolution by League =====\")\n",
    "    visualize_team_evolution_by_league_static(all_team_positions, seasons_order=seasons)\n",
    "\n",
    "    print(\"\\nDone!\")"
   ],
   "id": "fbc121e30a2defb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T05:40:37.807637Z",
     "start_time": "2025-03-04T16:46:57.707073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "\n",
    "# ====================== 计算防守统计数据 ======================\n",
    "def compute_defensive_stats(match_df, team_positions_df):\n",
    "    \"\"\"计算防守统计数据，包括各种比率和总丢球数，确保DataFrame结构正确。\"\"\"\n",
    "    epsilon = 1e-12\n",
    "    team_stats = {}\n",
    "    for team in team_positions_df['team_name'].unique():\n",
    "        team_stats[team] = {'total_goals_conceded': 0, 'ratio1_list': [], 'ratio2_list': [], 'ratio3_list': [],\n",
    "                            'ratio4_list': [], 'ratio5_list': [], 'ratio6_list': [], 'num_home_matches': 0}\n",
    "\n",
    "    # 处理主场比赛\n",
    "    home_matches = match_df.copy()\n",
    "    for idx, row in home_matches.iterrows():\n",
    "        home_team, away_team = row['home_team_name'], row['away_team_name']\n",
    "        if home_team not in team_stats or away_team not in team_stats:\n",
    "            print(f\"警告: 主队 {home_team} 或客队 {away_team} 未找到，跳过比赛 {idx}\")\n",
    "            continue\n",
    "        if row['Pre-Match PPG (Away)'] > 0:\n",
    "            team_stats[home_team]['ratio1_list'].append(\n",
    "                row['away_team_goal_count'] / (row['Pre-Match PPG (Away)'] + epsilon))\n",
    "        if row['away_team_corner_count'] > 0:\n",
    "            team_stats[home_team]['ratio2_list'].append(\n",
    "                row['away_team_goal_count'] / (row['away_team_corner_count'] + epsilon))\n",
    "        denominator = row['home_team_yellow_cards'] + row['home_team_red_cards'] + row['home_team_fouls'] + epsilon\n",
    "        team_stats[home_team]['ratio3_list'].append(row['away_team_goal_count'] / denominator)\n",
    "        if row['team_b_xg'] > 0:\n",
    "            team_stats[home_team]['ratio4_list'].append(row['away_team_goal_count'] / (row['team_b_xg'] + epsilon))\n",
    "        shots_total = row['away_team_shots_on_target'] + row['away_team_shots_off_target'] + epsilon\n",
    "        team_stats[home_team]['ratio5_list'].append(row['away_team_goal_count'] / shots_total)\n",
    "        if row['away_team_possession'] > 0:\n",
    "            team_stats[home_team]['ratio6_list'].append(\n",
    "                row['away_team_goal_count'] / (row['away_team_possession'] + epsilon))\n",
    "        team_stats[home_team]['total_goals_conceded'] += row['away_team_goal_count']\n",
    "        team_stats[home_team]['num_home_matches'] += 1\n",
    "\n",
    "    # 处理客场比赛\n",
    "    away_matches = match_df.copy()\n",
    "    for idx, row in away_matches.iterrows():\n",
    "        away_team = row['away_team_name']\n",
    "        if away_team not in team_stats:\n",
    "            print(f\"警告: 客队 {away_team} 未找到，跳过比赛 {idx}\")\n",
    "            continue\n",
    "        team_stats[away_team]['total_goals_conceded'] += row['home_team_goal_count']\n",
    "\n",
    "    # 计算平均比率并构建DataFrame\n",
    "    data = []\n",
    "    for team, stats in team_stats.items():\n",
    "        avg_ratio1 = np.mean(stats['ratio1_list']) if stats['ratio1_list'] else 0\n",
    "        avg_ratio2 = np.mean(stats['ratio2_list']) if stats['ratio2_list'] else 0\n",
    "        avg_ratio3 = np.mean(stats['ratio3_list']) if stats['ratio3_list'] else 0\n",
    "        avg_ratio4 = np.mean(stats['ratio4_list']) if stats['ratio4_list'] else 0\n",
    "        avg_ratio5 = np.mean(stats['ratio5_list']) if stats['ratio5_list'] else 0\n",
    "        avg_ratio6 = np.mean(stats['ratio6_list']) if stats['ratio6_list'] else 0\n",
    "        total_goals_conceded = stats['total_goals_conceded']\n",
    "        data.append({\n",
    "            'team_name': team,\n",
    "            'ratio1': avg_ratio1,\n",
    "            'ratio2': avg_ratio2,\n",
    "            'ratio3': avg_ratio3,\n",
    "            'ratio4': avg_ratio4,\n",
    "            'ratio5': avg_ratio5,\n",
    "            'ratio6': avg_ratio6,\n",
    "            'total_goals_conceded': total_goals_conceded\n",
    "        })\n",
    "\n",
    "    defensive_stats_df = pd.DataFrame(data)\n",
    "    return defensive_stats_df\n",
    "\n",
    "\n",
    "# ====================== ELO评分算法实现 ======================\n",
    "def initialize_elo_scores(team_positions_df):\n",
    "    teams = team_positions_df['team_name'].unique().tolist()\n",
    "    team_elo = {team: 1500 for team in teams}\n",
    "    for team in teams:\n",
    "        team_data = team_positions_df[team_positions_df['team_name'] == team]\n",
    "        rank = team_data['points_per_game'].rank().iloc[0]\n",
    "        team_elo[team] += (20 * (len(teams) - rank))\n",
    "    return team_elo\n",
    "\n",
    "\n",
    "def update_elo_scores(elo_scores, home_team, away_team, home_score, away_score, K=30):\n",
    "    home_elo = elo_scores[home_team]\n",
    "    away_elo = elo_scores[away_team]\n",
    "\n",
    "    expected_home = 1 / (1 + 10 ** ((away_elo - home_elo) / 400))\n",
    "    expected_away = 1 / (1 + 10 ** ((home_elo - away_elo) / 400))\n",
    "\n",
    "    if home_score > away_score:\n",
    "        elo_scores[home_team] += K * (1 - expected_home)\n",
    "        elo_scores[away_team] += K * (0 - expected_away)\n",
    "    elif home_score < away_score:\n",
    "        elo_scores[home_team] += K * (0 - expected_home)\n",
    "        elo_scores[away_team] += K * (1 - expected_away)\n",
    "    else:\n",
    "        elo_scores[home_team] += K * (0.5 - expected_home)\n",
    "        elo_scores[away_team] += K * (0.5 - expected_away)\n",
    "\n",
    "    return elo_scores\n",
    "\n",
    "\n",
    "# ====================== 数据加载函数 ======================\n",
    "def load_all_league_data(base_path, leagues, seasons):\n",
    "    all_team_positions = []\n",
    "    all_match_positions = []\n",
    "    for country_name, league_name in leagues:\n",
    "        for season in seasons:\n",
    "            print(f\"加载数据: {country_name} - {league_name} - {season}\")\n",
    "            team_file = os.path.join(base_path, f\"{country_name}-{league_name}-teams-{season}-stats.csv\")\n",
    "            match_file = os.path.join(base_path, f\"{country_name}-{league_name}-matches-{season}-stats.csv\")\n",
    "            if not os.path.exists(team_file) or not os.path.exists(match_file):\n",
    "                print(f\"警告: {country_name} - {league_name} - {season} 文件缺失\")\n",
    "                continue\n",
    "\n",
    "            team_df = pd.read_csv(team_file)\n",
    "            match_df = pd.read_csv(match_file)\n",
    "\n",
    "            # 标准化球队名称\n",
    "            team_df['team_name'] = team_df.get('common_name', team_df.get('team_name', None)).str.strip().str.lower()\n",
    "            match_df['home_team_name'] = match_df['home_team_name'].str.strip().str.lower()\n",
    "            match_df['away_team_name'] = match_df['away_team_name'].str.strip().str.lower()\n",
    "\n",
    "            team_names = team_df['team_name'].unique()\n",
    "            original_match_count = len(match_df)\n",
    "            match_df = match_df[\n",
    "                match_df['home_team_name'].isin(team_names) & match_df['away_team_name'].isin(team_names)]\n",
    "            if len(match_df) < original_match_count:\n",
    "                print(f\"警告: 由于球队缺失，过滤了 {original_match_count - len(match_df)} 场比赛\")\n",
    "\n",
    "            if match_df.empty:\n",
    "                print(\"警告: 此联赛和赛季没有有效比赛\")\n",
    "                continue\n",
    "\n",
    "            # 计算防守统计\n",
    "            defensive_stats_df = compute_defensive_stats(match_df, team_df)\n",
    "            if defensive_stats_df.empty:\n",
    "                print(\"警告: 此联赛和赛季未计算出防守统计，跳过\")\n",
    "                continue\n",
    "\n",
    "            team_df = team_df.merge(defensive_stats_df, on='team_name', how='left', suffixes=('', '_def'))\n",
    "            for col in ['ratio1', 'ratio2', 'ratio3', 'ratio4', 'ratio5', 'ratio6', 'total_goals_conceded']:\n",
    "                if f'{col}_def' in team_df.columns:\n",
    "                    team_df[col] = team_df[f'{col}_def']\n",
    "                    team_df.drop(f'{col}_def', axis=1, inplace=True)\n",
    "\n",
    "            # 计算标准化防守得分\n",
    "            max_total_goals = team_df['total_goals_conceded'].max()\n",
    "            min_total_goals = team_df['total_goals_conceded'].min()\n",
    "            if max_total_goals != min_total_goals:\n",
    "                team_df['normalized_defense_score'] = (max_total_goals - team_df['total_goals_conceded']) / (\n",
    "                            max_total_goals - min_total_goals + 1e-12)\n",
    "            else:\n",
    "                team_df['normalized_defense_score'] = 0\n",
    "\n",
    "            # 标准化防守数据并应用PCA\n",
    "            defensive_columns = [\n",
    "                'goals_conceded', 'goals_conceded_home', 'goals_conceded_away',\n",
    "                'goals_conceded_per_match', 'goals_conceded_per_match_home', 'goals_conceded_per_match_away',\n",
    "                'clean_sheets', 'clean_sheets_home', 'clean_sheets_away',\n",
    "                'clean_sheet_percentage', 'clean_sheet_percentage_home', 'clean_sheet_percentage_away',\n",
    "                'minutes_per_goal_conceded', 'minutes_per_goal_conceded_home', 'minutes_per_goal_conceded_away',\n",
    "                'goals_conceded_half_time', 'goals_conceded_half_time_home', 'goals_conceded_half_time_away',\n",
    "                'clean_sheet_half_time', 'clean_sheet_half_time_percentage',\n",
    "                'fouls', 'fouls_home', 'fouls_away', 'cards_total', 'cards_total_home', 'cards_total_away',\n",
    "                'xg_against_avg_overall', 'xg_against_avg_home', 'xg_against_avg_away',\n",
    "                'total_goals_conceded', 'ratio1', 'ratio2', 'ratio3', 'ratio4', 'ratio5', 'ratio6',\n",
    "                'normalized_defense_score'\n",
    "            ]\n",
    "            team_df_defensive = team_df[defensive_columns].fillna(0)\n",
    "            scaler_defense = StandardScaler()\n",
    "            X_scaled_defense = scaler_defense.fit_transform(team_df_defensive)\n",
    "            pca_defense = PCA(n_components=2)\n",
    "            X_pca_defense = pca_defense.fit_transform(X_scaled_defense)\n",
    "\n",
    "            # 创建球队位置数据\n",
    "            team_positions = pd.DataFrame({\n",
    "                'team_name': team_df['team_name'],\n",
    "                'PC1': X_pca_defense[:, 0],\n",
    "                'PC2': X_pca_defense[:, 1],\n",
    "                'points_per_game': team_df['points_per_game'],\n",
    "                'league': league_name,\n",
    "                'season': season,\n",
    "                'ratio1': team_df['ratio1'],\n",
    "                'ratio2': team_df['ratio2'],\n",
    "                'ratio3': team_df['ratio3'],\n",
    "                'ratio4': team_df['ratio4'],\n",
    "                'ratio5': team_df['ratio5'],\n",
    "                'ratio6': team_df['ratio6'],\n",
    "                'normalized_defense_score': team_df['normalized_defense_score']\n",
    "            })\n",
    "            team_positions['team_season'] = league_name + '_' + team_positions['team_name'] + '_' + team_positions[\n",
    "                'season']\n",
    "            all_team_positions.append(team_positions)\n",
    "\n",
    "            # 处理比赛数据\n",
    "            irrelevant_cols = ['timestamp', 'date_GMT', 'status', 'attendance', 'referee', 'stadium_name', 'Game Week']\n",
    "            match_df = match_df.drop(columns=irrelevant_cols, errors='ignore')\n",
    "            for col in match_df.columns:\n",
    "                match_df[col] = match_df[col].astype(str).str.replace(',', '.', regex=True)\n",
    "                try:\n",
    "                    match_df[col] = pd.to_numeric(match_df[col])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            numeric_cols = match_df.select_dtypes(include=[np.number]).columns\n",
    "            match_df[numeric_cols] = match_df[numeric_cols].fillna(match_df[numeric_cols].mean())\n",
    "            scaler_match = StandardScaler()\n",
    "            X_scaled_match = scaler_match.fit_transform(match_df[numeric_cols])\n",
    "            pca_match = PCA(n_components=2)\n",
    "            X_pca_match = pca_match.fit_transform(X_scaled_match)\n",
    "            match_positions = pd.DataFrame({\n",
    "                'home_team_name': match_df['home_team_name'],\n",
    "                'away_team_name': match_df['away_team_name'],\n",
    "                'PC1': X_pca_match[:, 0],\n",
    "                'PC2': X_pca_match[:, 1],\n",
    "                'league': league_name,\n",
    "                'season': season\n",
    "            })\n",
    "            all_match_positions.append(match_positions)\n",
    "    combined_team_positions = pd.concat(all_team_positions, ignore_index=True)\n",
    "    combined_match_positions = pd.concat(all_match_positions, ignore_index=True)\n",
    "    return combined_team_positions, combined_match_positions\n",
    "\n",
    "\n",
    "# ====================== 修改后的损失函数 ======================\n",
    "def compute_total_loss(positions, match_home_idx, match_away_idx, match_PC1, match_PC2, points_per_game, rank_scale,\n",
    "                       ratios, w, normalized_defense_score, lambda_defense, lambda_supervision, elo_scores, alpha=2.0,\n",
    "                       max_match_loss=1.0, max_defense_loss=1.0, max_supervision_loss=1.0):\n",
    "    \"\"\"\n",
    "    计算总损失函数，所有损失项归一化后控制在 [0, 1] 范围内。\n",
    "    \n",
    "    参数：\n",
    "        positions: 球队位置 (num_teams, 2)\n",
    "        match_home_idx, match_away_idx: 主客队索引\n",
    "        match_PC1, match_PC2: 比赛数据的 PCA 坐标\n",
    "        points_per_game: 每场比赛得分\n",
    "        rank_scale: 排名缩放因子\n",
    "        ratios: 防守比率数据 (num_teams, 6)\n",
    "        w: 防守比率权重 (6,)\n",
    "        normalized_defense_score: 标准化防守得分\n",
    "        lambda_defense, lambda_supervision: 超参数\n",
    "        elo_scores: ELO 评分\n",
    "        alpha: 超参数，默认 2.0\n",
    "        max_match_loss, max_defense_loss, max_supervision_loss: 各损失项的最大值，用于归一化\n",
    "        \n",
    "    返回：\n",
    "        total_loss: 总损失值，范围控制在 [0, 1] 内\n",
    "    \"\"\"\n",
    "    epsilon = 1e-12\n",
    "    num_matches = tf.shape(match_home_idx)[0]\n",
    "    if num_matches == 0:\n",
    "        return tf.constant(0.0, dtype=tf.float32)\n",
    "\n",
    "    # 计算比赛损失\n",
    "    home_pos = tf.gather(positions, match_home_idx)\n",
    "    away_pos = tf.gather(positions, match_away_idx)\n",
    "    match_points = tf.stack([match_PC1, match_PC2], axis=1)\n",
    "    dist_home = tf.norm(home_pos - match_points, axis=1)\n",
    "    dist_away = tf.norm(away_pos - match_points, axis=1)\n",
    "    all_distances = tf.concat([dist_home, dist_away], axis=0)\n",
    "    min_dist = tf.reduce_min(all_distances)\n",
    "    max_dist = tf.reduce_max(all_distances)\n",
    "    dist_range = max_dist - min_dist + epsilon\n",
    "    dist_home_norm = (dist_home - min_dist) / dist_range\n",
    "    dist_away_norm = (dist_away - min_dist) / dist_range\n",
    "\n",
    "    home_elo = tf.gather(elo_scores, match_home_idx)\n",
    "    away_elo = tf.gather(elo_scores, match_away_idx)\n",
    "    elo_diff = tf.abs(home_elo - away_elo)\n",
    "    weight = 1.0 / (1.0 + elo_diff * rank_scale)\n",
    "    match_loss = weight * (dist_home_norm + dist_away_norm)\n",
    "    match_loss_mean = tf.reduce_mean(match_loss)\n",
    "    match_loss_norm = match_loss_mean / max_match_loss\n",
    "\n",
    "    # 计算防守损失\n",
    "    ratios = tf.ensure_shape(ratios, [None, 6])\n",
    "    w = tf.reshape(w, [6])\n",
    "    defense_target = -tf.reduce_sum(w * ratios, axis=1)\n",
    "    defense_loss = tf.reduce_mean(tf.square(positions[:, 1] - defense_target))\n",
    "    defense_loss_norm = defense_loss / max_defense_loss\n",
    "\n",
    "    # 计算监督损失\n",
    "    supervision_loss = tf.reduce_mean(tf.square(defense_target - normalized_defense_score))\n",
    "    supervision_loss_norm = supervision_loss / max_supervision_loss\n",
    "\n",
    "    # 总损失\n",
    "    total_loss = match_loss_norm + lambda_defense * defense_loss_norm + lambda_supervision * supervision_loss_norm\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def compute_max_losses(team_positions_df, match_positions_df, **kwargs):\n",
    "    \"\"\"计算训练集中各损失项的最大值\"\"\"\n",
    "    team_seasons = team_positions_df['team_season'].unique()\n",
    "    team_season_to_idx = {t: i for i, t in enumerate(team_seasons)}\n",
    "    positions = tf.constant(team_positions_df[['PC1', 'PC2']].values, dtype=tf.float32)\n",
    "    points_per_game = tf.constant(team_positions_df['points_per_game'].values, dtype=tf.float32)\n",
    "    ratios = tf.constant(team_positions_df[['ratio1', 'ratio2', 'ratio3', 'ratio4', 'ratio5', 'ratio6']].values,\n",
    "                         dtype=tf.float32)\n",
    "    normalized_defense_score = tf.constant(team_positions_df['normalized_defense_score'].values, dtype=tf.float32)\n",
    "\n",
    "    elo_scores_dict = initialize_elo_scores(team_positions_df)\n",
    "    team_names = [t.split('_')[1] for t in team_seasons]\n",
    "    elo_scores = tf.convert_to_tensor([elo_scores_dict[name] for name in team_names], dtype=tf.float32)\n",
    "\n",
    "    match_array = []\n",
    "    for _, row in match_positions_df.iterrows():\n",
    "        hname, aname = row['home_team_name'], row['away_team_name']\n",
    "        season, league = row['season'], row['league']\n",
    "        team_season_h = f\"{league}_{hname}_{season}\"\n",
    "        team_season_a = f\"{league}_{aname}_{season}\"\n",
    "        if team_season_h in team_season_to_idx and team_season_a in team_season_to_idx:\n",
    "            match_array.append(\n",
    "                [team_season_to_idx[team_season_h], team_season_to_idx[team_season_a], row['PC1'], row['PC2']])\n",
    "    match_array = np.array(match_array, dtype=np.float32)\n",
    "    match_home_idx = tf.constant(match_array[:, 0], dtype=tf.int32)\n",
    "    match_away_idx = tf.constant(match_array[:, 1], dtype=tf.int32)\n",
    "    match_PC1 = tf.constant(match_array[:, 2], dtype=tf.float32)\n",
    "    match_PC2 = tf.constant(match_array[:, 3], dtype=tf.float32)\n",
    "\n",
    "    w = tf.ones([6], dtype=tf.float32)\n",
    "    rank_scale = tf.constant(1.0, dtype=tf.float32)\n",
    "\n",
    "    match_loss = tf.reduce_mean(\n",
    "        compute_match_loss(positions, match_home_idx, match_away_idx, match_PC1, match_PC2, elo_scores, rank_scale))\n",
    "    defense_loss = tf.reduce_mean(tf.square(positions[:, 1] - (-tf.reduce_sum(w * ratios, axis=1))))\n",
    "    supervision_loss = tf.reduce_mean(tf.square((-tf.reduce_sum(w * ratios, axis=1)) - normalized_defense_score))\n",
    "\n",
    "    return float(match_loss), float(defense_loss), float(supervision_loss)\n",
    "\n",
    "\n",
    "def compute_match_loss(positions, match_home_idx, match_away_idx, match_PC1, match_PC2, elo_scores, rank_scale):\n",
    "    home_pos = tf.gather(positions, match_home_idx)\n",
    "    away_pos = tf.gather(positions, match_away_idx)\n",
    "    match_points = tf.stack([match_PC1, match_PC2], axis=1)\n",
    "    dist_home = tf.norm(home_pos - match_points, axis=1)\n",
    "    dist_away = tf.norm(away_pos - match_points, axis=1)\n",
    "    all_distances = tf.concat([dist_home, dist_away], axis=0)\n",
    "    min_dist = tf.reduce_min(all_distances)\n",
    "    max_dist = tf.reduce_max(all_distances)\n",
    "    dist_range = max_dist - min_dist + 1e-12\n",
    "    dist_home_norm = (dist_home - min_dist) / dist_range\n",
    "    dist_away_norm = (dist_away - min_dist) / dist_range\n",
    "    home_elo = tf.gather(elo_scores, match_home_idx)\n",
    "    away_elo = tf.gather(elo_scores, match_away_idx)\n",
    "    elo_diff = tf.abs(home_elo - away_elo)\n",
    "    weight = 1.0 / (1.0 + elo_diff * rank_scale)\n",
    "    return weight * (dist_home_norm + dist_away_norm)\n",
    "\n",
    "\n",
    "# ====================== Adam优化函数 ======================\n",
    "def adam_optimize_positions(team_positions_df, match_positions_df, initial_lr=0.001, decay_steps=50000, decay_rate=0.80,\n",
    "                            clipnorm=1.0, iterations=50000, verbose_interval=500, random_seed=42,\n",
    "                            lambda_defense=0.1, lambda_supervision=0.1, alpha=2.0,\n",
    "                            max_match_loss=1.0, max_defense_loss=1.0, max_supervision_loss=1.0):\n",
    "    \"\"\"使用Adam优化器训练模型，更新球队坐标、rank_scale和权重w。\"\"\"\n",
    "    team_seasons = team_positions_df['team_season'].unique()\n",
    "    team_season_to_idx = {t: i for i, t in enumerate(team_seasons)}\n",
    "    num_teams = len(team_seasons)\n",
    "\n",
    "    elo_scores_dict = initialize_elo_scores(team_positions_df)\n",
    "    team_names_for_seasons = [t.split('_')[1] for t in team_seasons]\n",
    "    elo_scores = tf.convert_to_tensor([elo_scores_dict[team_name] for team_name in team_names_for_seasons],\n",
    "                                      dtype=tf.float32)\n",
    "\n",
    "    team_positions_df = team_positions_df.set_index('team_season')\n",
    "    init_positions = np.zeros((num_teams, 2), dtype=np.float32)\n",
    "    init_points_pg = np.zeros((num_teams,), dtype=np.float32)\n",
    "    ratios_df = team_positions_df[['ratio1', 'ratio2', 'ratio3', 'ratio4', 'ratio5', 'ratio6']]\n",
    "    ratios = tf.constant(ratios_df.values, dtype=tf.float32)\n",
    "    normalized_defense_score = tf.constant(team_positions_df['normalized_defense_score'].values, dtype=tf.float32)\n",
    "\n",
    "    for i, team_season in enumerate(team_seasons):\n",
    "        row = team_positions_df.loc[team_season]\n",
    "        init_positions[i, 0] = row['PC1']\n",
    "        init_positions[i, 1] = row['PC2']\n",
    "        init_points_pg[i] = row['points_per_game']\n",
    "\n",
    "    match_array = []\n",
    "    for idx, row in match_positions_df.iterrows():\n",
    "        hname = row['home_team_name']\n",
    "        aname = row['away_team_name']\n",
    "        season = row['season']\n",
    "        league = row['league']\n",
    "        team_season_h = f\"{league}_{hname}_{season}\"\n",
    "        team_season_a = f\"{league}_{aname}_{season}\"\n",
    "        if team_season_h in team_season_to_idx and team_season_a in team_season_to_idx:\n",
    "            h_idx = team_season_to_idx[team_season_h]\n",
    "            a_idx = team_season_to_idx[team_season_a]\n",
    "            match_array.append([h_idx, a_idx, row['PC1'], row['PC2']])\n",
    "    match_array = np.array(match_array, dtype=np.float32)\n",
    "    if len(match_array) == 0:\n",
    "        print(\"警告: 训练中未找到有效比赛！\")\n",
    "        return [], team_positions_df.reset_index(), None, None\n",
    "    match_home_idx = tf.constant(match_array[:, 0], dtype=tf.int32)\n",
    "    match_away_idx = tf.constant(match_array[:, 1], dtype=tf.int32)\n",
    "    match_PC1 = tf.constant(match_array[:, 2], dtype=tf.float32)\n",
    "    match_PC2 = tf.constant(match_array[:, 3], dtype=tf.float32)\n",
    "    points_per_game = tf.constant(init_points_pg, dtype=tf.float32)\n",
    "\n",
    "    tf.random.set_seed(random_seed)\n",
    "    positions = tf.Variable(init_positions, name=\"positions\", dtype=tf.float32)\n",
    "    rank_scale = tf.Variable(1.0, name=\"rank_scale\", dtype=tf.float32)\n",
    "    w = tf.Variable(np.random.randn(6) * 0.01, name=\"weights\", dtype=tf.float32)\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_lr, decay_steps, decay_rate, staircase=False)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, clipnorm=clipnorm)\n",
    "\n",
    "    losses = []\n",
    "    best_loss = np.inf\n",
    "    best_positions = None\n",
    "    best_rank_scale = None\n",
    "    best_w = None\n",
    "\n",
    "    for i in range(iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = compute_total_loss(positions, match_home_idx, match_away_idx, match_PC1, match_PC2, points_per_game,\n",
    "                                      rank_scale, ratios, w, normalized_defense_score, lambda_defense,\n",
    "                                      lambda_supervision,\n",
    "                                      elo_scores, alpha, max_match_loss, max_defense_loss, max_supervision_loss)\n",
    "        grads = tape.gradient(loss, [positions, rank_scale, w])\n",
    "        optimizer.apply_gradients(zip(grads, [positions, rank_scale, w]))\n",
    "        loss_val = float(loss.numpy())\n",
    "        losses.append(loss_val)\n",
    "        if loss_val < best_loss:\n",
    "            best_loss = loss_val\n",
    "            best_positions = positions.numpy().copy()\n",
    "            best_rank_scale = float(rank_scale.numpy())\n",
    "            best_w = w.numpy().copy()\n",
    "        if (i + 1) % verbose_interval == 0:\n",
    "            step = optimizer.iterations.numpy()\n",
    "            current_lr = lr_schedule(step).numpy()\n",
    "            print(\n",
    "                f\"迭代 {i + 1}/{iterations}, 损失 = {loss_val:.4f}, 学习率 = {current_lr:.6f}, rank_scale = {rank_scale.numpy():.4f}\")\n",
    "\n",
    "    positions.assign(best_positions)\n",
    "    rank_scale.assign(best_rank_scale)\n",
    "    w.assign(best_w)\n",
    "    print(f\"=> 训练完成, 最佳损失={best_loss:.4f}, 最佳 rank_scale={best_rank_scale:.4f}\")\n",
    "\n",
    "    final_pos = positions.numpy()\n",
    "    for idx, team_season in enumerate(team_seasons):\n",
    "        team_positions_df.loc[team_season, 'PC1'] = final_pos[idx, 0]\n",
    "        team_positions_df.loc[team_season, 'PC2'] = final_pos[idx, 1]\n",
    "    team_positions_df = team_positions_df.reset_index()\n",
    "    team_positions_df.to_csv(\"trained_team_positions.csv\", index=False)\n",
    "    with open(\"best_rank_scale.txt\", \"w\") as f:\n",
    "        f.write(str(best_rank_scale))\n",
    "\n",
    "    return losses, team_positions_df, best_rank_scale, best_w\n",
    "\n",
    "\n",
    "# ====================== 交叉验证与网格搜索函数 ======================\n",
    "def run_cross_validation(team_positions, match_positions, n_splits=3, test_size=0.2,\n",
    "                         random_state=42, lambda_defense_values=[0.01, 0.1, 1.0], \n",
    "                         lambda_supervision_values=[0.01, 0.1, 1.0], **opt_kwargs):\n",
    "    \"\"\"\n",
    "    执行交叉验证并进行超参数网格搜索。\n",
    "    \n",
    "    参数：\n",
    "        team_positions (pd.DataFrame): 球队位置数据\n",
    "        match_positions (pd.DataFrame): 比赛数据\n",
    "        n_splits (int): 交叉验证拆分次数\n",
    "        test_size (float): 测试集比例\n",
    "        random_state (int): 随机种子\n",
    "        lambda_defense_values (list): 防守损失权重的候选值\n",
    "        lambda_supervision_values (list): 监督损失权重的候选值\n",
    "        **opt_kwargs: 传递给 adam_optimize_positions 的其他参数\n",
    "        \n",
    "    返回：\n",
    "        best_params (tuple): 最佳超参数组合 (lambda_defense, lambda_supervision)\n",
    "    \"\"\"\n",
    "    best_params = None\n",
    "    best_test_loss = np.inf\n",
    "    param_combinations = list(product(lambda_defense_values, lambda_supervision_values))\n",
    "\n",
    "    for lambda_defense, lambda_supervision in param_combinations:\n",
    "        print(f\"\\n===== 网格搜索: lambda_defense={lambda_defense}, lambda_supervision={lambda_supervision} =====\")\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        matches_df_all = match_positions.copy()\n",
    "        all_indices = matches_df_all.index.values\n",
    "\n",
    "        for i in range(n_splits):\n",
    "            print(f\"\\n===== 第 {i + 1}/{n_splits} 次拆分 =====\")\n",
    "            idx_train, idx_test = train_test_split(all_indices, test_size=test_size, random_state=random_state + i)\n",
    "            train_matches_df = matches_df_all.loc[idx_train].copy()\n",
    "            test_matches_df = matches_df_all.loc[idx_test].copy()\n",
    "\n",
    "            max_match_loss, max_defense_loss, max_supervision_loss = compute_max_losses(team_positions, train_matches_df)\n",
    "\n",
    "            losses, best_positions_df, best_scale_val, w_trained = adam_optimize_positions(\n",
    "                team_positions.copy(), train_matches_df, lambda_defense=lambda_defense,\n",
    "                lambda_supervision=lambda_supervision, max_match_loss=max_match_loss,\n",
    "                max_defense_loss=max_defense_loss, max_supervision_loss=max_supervision_loss, **opt_kwargs)\n",
    "            if not losses:\n",
    "                print(\"警告: 此拆分中没有有效训练数据，跳过此拆分。\")\n",
    "                train_losses.append(np.nan)\n",
    "                test_losses.append(np.nan)\n",
    "                continue\n",
    "            train_losses.append(losses[-1])\n",
    "\n",
    "            elo_scores_dict = initialize_elo_scores(best_positions_df)\n",
    "            team_seasons_test = best_positions_df['team_season'].unique().tolist()\n",
    "            team_names_for_seasons_test = [team.split('_')[1] for team in team_seasons_test]\n",
    "            elo_scores_test = tf.convert_to_tensor(\n",
    "                [elo_scores_dict[team_name] for team_name in team_names_for_seasons_test], dtype=tf.float32)\n",
    "\n",
    "            best_positions_df = best_positions_df.set_index('team_season')\n",
    "            final_positions = best_positions_df[['PC1', 'PC2']].values\n",
    "            final_points_pg = best_positions_df['points_per_game'].values\n",
    "            ratios_df = best_positions_df[['ratio1', 'ratio2', 'ratio3', 'ratio4', 'ratio5', 'ratio6']].values\n",
    "            normalized_defense_score = best_positions_df['normalized_defense_score'].values\n",
    "\n",
    "            match_array_test = []\n",
    "            for idx, row in test_matches_df.iterrows():\n",
    "                hname = row['home_team_name']\n",
    "                aname = row['away_team_name']\n",
    "                season = row['season']\n",
    "                league = row['league']\n",
    "                team_season_h = f\"{league}_{hname}_{season}\"\n",
    "                team_season_a = f\"{league}_{aname}_{season}\"\n",
    "                if team_season_h in team_seasons_test and team_season_a in team_seasons_test:\n",
    "                    h_idx = team_seasons_test.index(team_season_h)\n",
    "                    a_idx = team_seasons_test.index(team_season_a)\n",
    "                    match_array_test.append([h_idx, a_idx, row['PC1'], row['PC2']])\n",
    "            match_array_test = np.array(match_array_test, dtype=np.float32)\n",
    "            if len(match_array_test) == 0:\n",
    "                print(\"警告: 此拆分中没有有效测试比赛！\")\n",
    "                test_losses.append(np.nan)\n",
    "                continue\n",
    "\n",
    "            match_home_idx_test = tf.constant(match_array_test[:, 0], dtype=tf.int32)\n",
    "            match_away_idx_test = tf.constant(match_array_test[:, 1], dtype=tf.int32)\n",
    "            match_PC1_test = tf.constant(match_array_test[:, 2], dtype=tf.float32)\n",
    "            match_PC2_test = tf.constant(match_array_test[:, 3], dtype=tf.float32)\n",
    "\n",
    "            positions_tf = tf.constant(final_positions, dtype=tf.float32)\n",
    "            points_pg_tf = tf.constant(final_points_pg, dtype=tf.float32)\n",
    "            ratios_tf = tf.constant(ratios_df, dtype=tf.float32)\n",
    "            normalized_defense_score_tf = tf.constant(normalized_defense_score, dtype=tf.float32)\n",
    "            rank_scale_tf = tf.constant(best_scale_val, dtype=tf.float32)\n",
    "            w_tf = tf.constant(w_trained, dtype=tf.float32)\n",
    "\n",
    "            test_loss_val = compute_total_loss(\n",
    "                positions_tf, match_home_idx_test, match_away_idx_test, match_PC1_test, match_PC2_test,\n",
    "                points_pg_tf, rank_scale_tf, ratios_tf, w_tf, normalized_defense_score_tf,\n",
    "                lambda_defense, lambda_supervision, elo_scores_test, alpha=2.0,\n",
    "                max_match_loss=max_match_loss, max_defense_loss=max_defense_loss, max_supervision_loss=max_supervision_loss\n",
    "            ).numpy()\n",
    "\n",
    "            test_losses.append(test_loss_val)\n",
    "            print(f\"第 {i + 1} 次拆分: 训练损失 = {train_losses[-1]:.4f}, 测试损失 = {test_loss_val:.4f}\")\n",
    "\n",
    "        valid_test_losses = [x for x in test_losses if not np.isnan(x)]\n",
    "        if valid_test_losses:\n",
    "            mean_test_loss = np.mean(valid_test_losses)\n",
    "            print(f\"lambda_defense={lambda_defense}, lambda_supervision={lambda_supervision} 的平均测试损失 = {mean_test_loss:.4f}\")\n",
    "            if mean_test_loss < best_test_loss:\n",
    "                best_test_loss = mean_test_loss\n",
    "                best_params = (lambda_defense, lambda_supervision)\n",
    "\n",
    "    print(f\"\\n最佳超参数: lambda_defense={best_params[0]}, lambda_supervision={best_params[1]}, 最佳测试损失={best_test_loss:.4f}\")\n",
    "    return best_params\n",
    "\n",
    "\n",
    "# ====================== 可视化函数 ======================\n",
    "def visualize_team_evolution_by_league_static(team_positions_df, seasons_order):\n",
    "    output_dir = \"/Users/peixuanma/Downloads/Output_Graphs\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    leagues = team_positions_df['league'].unique().tolist()\n",
    "    for league in leagues:\n",
    "        league_df = team_positions_df.loc[team_positions_df['league'] == league].copy()\n",
    "        team_counts = league_df.groupby(\"team_name\")[\"season\"].nunique()\n",
    "        valid_teams = team_counts[team_counts == len(seasons_order)].index.tolist()\n",
    "        if not valid_teams:\n",
    "            print(f\"{league} 中没有球队连续出现在所有赛季，使用所有球队。\")\n",
    "            valid_teams = league_df['team_name'].unique().tolist()\n",
    "        valid_df = league_df.loc[league_df[\"team_name\"].isin(valid_teams)].copy()\n",
    "        valid_df.loc[:, \"season\"] = pd.Categorical(valid_df[\"season\"], categories=seasons_order, ordered=True)\n",
    "        valid_df = valid_df.sort_values([\"team_name\", \"season\"])\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.title(f\"{league} - 球队演变 (进攻-防守)\")\n",
    "        plt.xlabel(\"PC1 (进攻)\")\n",
    "        plt.ylabel(\"PC2 (防守)\")\n",
    "        plt.grid(True)\n",
    "\n",
    "        teams = valid_df['team_name'].unique().tolist()\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(teams)))\n",
    "        team_colors = dict(zip(teams, colors))\n",
    "\n",
    "        for team in teams:\n",
    "            sub = valid_df.loc[valid_df['team_name'] == team].sort_values(\"season\")\n",
    "            plt.plot(sub['PC1'], sub['PC2'], marker='o', linestyle='-', color=team_colors[team], label=team)\n",
    "            for idx, row in sub.iterrows():\n",
    "                plt.text(row['PC1'], row['PC2'], str(row['season']), fontsize=8, ha='right', va='bottom')\n",
    "\n",
    "        plt.legend(fontsize=8, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        filename = os.path.join(output_dir, f\"{league}_evolution_static.png\")\n",
    "        plt.savefig(filename, dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"保存 {league} 的静态演变图 -> {filename}\")\n",
    "\n",
    "\n",
    "# ====================== 主函数 ======================\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = '/Users/peixuanma/Downloads/data1'\n",
    "    leagues = [\n",
    "        (\"england\", \"premier-league\"), (\"germany\", \"bundesliga\"), (\"spain\", \"la-liga\"),\n",
    "        (\"france\", \"ligue-1\"), (\"italy\", \"serie-a\"), (\"netherlands\", \"eredivisie\"),\n",
    "        (\"portugal\", \"ligapro\"), (\"denmark\", \"superliga\"), (\"england\", \"championship\"),\n",
    "        (\"portugal\", \"liga-nos\"), (\"italy\", \"serie-b\"), (\"germany\", \"2-bundesliga\")\n",
    "    ]\n",
    "    seasons = [\n",
    "        \"2013-to-2014\", \"2014-to-2015\", \"2015-to-2016\", \"2016-to-2017\", \"2017-to-2018\",\n",
    "        \"2018-to-2019\", \"2020-to-2021\", \"2021-to-2022\", \"2022-to-2023\", \"2023-to-2024\"\n",
    "    ]\n",
    "\n",
    "    # 第1步：加载数据\n",
    "    all_team_positions, all_match_positions = load_all_league_data(base_path, leagues, seasons)\n",
    "\n",
    "    # 第2步：网格搜索超参数（修改范围）\n",
    "    print(\"\\n===== 运行网格搜索 =====\")\n",
    "    lambda_defense_values = [0.001, 0.005, 0.01, 0.5, 1.0]  # 扩展范围\n",
    "    lambda_supervision_values = [0.001, 0.005, 0.01, 0.5, 1.0]  # 扩展范围\n",
    "    best_params = run_cross_validation(\n",
    "        team_positions=all_team_positions, match_positions=all_match_positions,\n",
    "        n_splits=3, test_size=0.2, random_state=42,\n",
    "        lambda_defense_values=lambda_defense_values, lambda_supervision_values=lambda_supervision_values,\n",
    "        initial_lr=0.001, decay_steps=50000, decay_rate=0.80,\n",
    "        clipnorm=1.0, iterations=50000, verbose_interval=5000, alpha=2.0\n",
    "    )\n",
    "\n",
    "    # 第3步：使用最佳超参数训练最终模型\n",
    "    print(\"\\n===== 使用最佳超参数训练最终模型 =====\")\n",
    "    lambda_defense, lambda_supervision = best_params\n",
    "    max_match_loss, max_defense_loss, max_supervision_loss = compute_max_losses(all_team_positions, all_match_positions)\n",
    "    final_losses, final_team_positions, final_rank_scale, final_w = adam_optimize_positions(\n",
    "        all_team_positions.copy(), all_match_positions.copy(),\n",
    "        initial_lr=0.001, decay_steps=50000, decay_rate=0.80,\n",
    "        clipnorm=1.0, iterations=50000, verbose_interval=5000, random_seed=42,\n",
    "        lambda_defense=lambda_defense, lambda_supervision=lambda_supervision, alpha=2.0,\n",
    "        max_match_loss=max_match_loss, max_defense_loss=max_defense_loss, max_supervision_loss=max_supervision_loss\n",
    "    )\n",
    "    if final_losses:\n",
    "        final_team_positions.to_csv(\"trained_team_positions.csv\", index=False)\n",
    "        with open(\"best_rank_scale.txt\", \"w\") as f:\n",
    "            f.write(str(final_rank_scale))\n",
    "        print(f\"最终训练损失: {final_losses[-1]:.4f}, 最佳 rank_scale: {final_rank_scale:.4f}\")\n",
    "\n",
    "    # 第4步：可视化\n",
    "    print(\"\\n===== 按联赛可视化球队演变 =====\")\n",
    "    visualize_team_evolution_by_league_static(final_team_positions, seasons_order=seasons)\n",
    "\n",
    "    print(\"\\n完成！\")"
   ],
   "id": "1dad320ae92d2bed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据: england - premier-league - 2013-to-2014\n",
      "加载数据: england - premier-league - 2014-to-2015\n",
      "加载数据: england - premier-league - 2015-to-2016\n",
      "加载数据: england - premier-league - 2016-to-2017\n",
      "加载数据: england - premier-league - 2017-to-2018\n",
      "加载数据: england - premier-league - 2018-to-2019\n",
      "加载数据: england - premier-league - 2020-to-2021\n",
      "加载数据: england - premier-league - 2021-to-2022\n",
      "加载数据: england - premier-league - 2022-to-2023\n",
      "加载数据: england - premier-league - 2023-to-2024\n",
      "加载数据: germany - bundesliga - 2013-to-2014\n",
      "加载数据: germany - bundesliga - 2014-to-2015\n",
      "加载数据: germany - bundesliga - 2015-to-2016\n",
      "加载数据: germany - bundesliga - 2016-to-2017\n",
      "加载数据: germany - bundesliga - 2017-to-2018\n",
      "加载数据: germany - bundesliga - 2018-to-2019\n",
      "加载数据: germany - bundesliga - 2020-to-2021\n",
      "加载数据: germany - bundesliga - 2021-to-2022\n",
      "加载数据: germany - bundesliga - 2022-to-2023\n",
      "加载数据: germany - bundesliga - 2023-to-2024\n",
      "加载数据: spain - la-liga - 2013-to-2014\n",
      "加载数据: spain - la-liga - 2014-to-2015\n",
      "加载数据: spain - la-liga - 2015-to-2016\n",
      "加载数据: spain - la-liga - 2016-to-2017\n",
      "加载数据: spain - la-liga - 2017-to-2018\n",
      "加载数据: spain - la-liga - 2018-to-2019\n",
      "加载数据: spain - la-liga - 2020-to-2021\n",
      "加载数据: spain - la-liga - 2021-to-2022\n",
      "加载数据: spain - la-liga - 2022-to-2023\n",
      "加载数据: spain - la-liga - 2023-to-2024\n",
      "加载数据: france - ligue-1 - 2013-to-2014\n",
      "加载数据: france - ligue-1 - 2014-to-2015\n",
      "加载数据: france - ligue-1 - 2015-to-2016\n",
      "加载数据: france - ligue-1 - 2016-to-2017\n",
      "加载数据: france - ligue-1 - 2017-to-2018\n",
      "加载数据: france - ligue-1 - 2018-to-2019\n",
      "加载数据: france - ligue-1 - 2020-to-2021\n",
      "加载数据: france - ligue-1 - 2021-to-2022\n",
      "加载数据: france - ligue-1 - 2022-to-2023\n",
      "加载数据: france - ligue-1 - 2023-to-2024\n",
      "加载数据: italy - serie-a - 2013-to-2014\n",
      "加载数据: italy - serie-a - 2014-to-2015\n",
      "加载数据: italy - serie-a - 2015-to-2016\n",
      "加载数据: italy - serie-a - 2016-to-2017\n",
      "加载数据: italy - serie-a - 2017-to-2018\n",
      "加载数据: italy - serie-a - 2018-to-2019\n",
      "加载数据: italy - serie-a - 2020-to-2021\n",
      "加载数据: italy - serie-a - 2021-to-2022\n",
      "加载数据: italy - serie-a - 2022-to-2023\n",
      "加载数据: italy - serie-a - 2023-to-2024\n",
      "加载数据: netherlands - eredivisie - 2013-to-2014\n",
      "加载数据: netherlands - eredivisie - 2014-to-2015\n",
      "加载数据: netherlands - eredivisie - 2015-to-2016\n",
      "加载数据: netherlands - eredivisie - 2016-to-2017\n",
      "加载数据: netherlands - eredivisie - 2017-to-2018\n",
      "加载数据: netherlands - eredivisie - 2018-to-2019\n",
      "加载数据: netherlands - eredivisie - 2020-to-2021\n",
      "加载数据: netherlands - eredivisie - 2021-to-2022\n",
      "加载数据: netherlands - eredivisie - 2022-to-2023\n",
      "加载数据: netherlands - eredivisie - 2023-to-2024\n",
      "加载数据: portugal - ligapro - 2013-to-2014\n",
      "警告: portugal - ligapro - 2013-to-2014 文件缺失\n",
      "加载数据: portugal - ligapro - 2014-to-2015\n",
      "加载数据: portugal - ligapro - 2015-to-2016\n",
      "加载数据: portugal - ligapro - 2016-to-2017\n",
      "加载数据: portugal - ligapro - 2017-to-2018\n",
      "加载数据: portugal - ligapro - 2018-to-2019\n",
      "加载数据: portugal - ligapro - 2020-to-2021\n",
      "加载数据: portugal - ligapro - 2021-to-2022\n",
      "加载数据: portugal - ligapro - 2022-to-2023\n",
      "加载数据: portugal - ligapro - 2023-to-2024\n",
      "加载数据: denmark - superliga - 2013-to-2014\n",
      "加载数据: denmark - superliga - 2014-to-2015\n",
      "加载数据: denmark - superliga - 2015-to-2016\n",
      "加载数据: denmark - superliga - 2016-to-2017\n",
      "加载数据: denmark - superliga - 2017-to-2018\n",
      "加载数据: denmark - superliga - 2018-to-2019\n",
      "加载数据: denmark - superliga - 2020-to-2021\n",
      "加载数据: denmark - superliga - 2021-to-2022\n",
      "加载数据: denmark - superliga - 2022-to-2023\n",
      "加载数据: denmark - superliga - 2023-to-2024\n",
      "加载数据: england - championship - 2013-to-2014\n",
      "加载数据: england - championship - 2014-to-2015\n",
      "加载数据: england - championship - 2015-to-2016\n",
      "加载数据: england - championship - 2016-to-2017\n",
      "加载数据: england - championship - 2017-to-2018\n",
      "加载数据: england - championship - 2018-to-2019\n",
      "加载数据: england - championship - 2020-to-2021\n",
      "加载数据: england - championship - 2021-to-2022\n",
      "加载数据: england - championship - 2022-to-2023\n",
      "加载数据: england - championship - 2023-to-2024\n",
      "加载数据: portugal - liga-nos - 2013-to-2014\n",
      "加载数据: portugal - liga-nos - 2014-to-2015\n",
      "加载数据: portugal - liga-nos - 2015-to-2016\n",
      "加载数据: portugal - liga-nos - 2016-to-2017\n",
      "加载数据: portugal - liga-nos - 2017-to-2018\n",
      "加载数据: portugal - liga-nos - 2018-to-2019\n",
      "加载数据: portugal - liga-nos - 2020-to-2021\n",
      "加载数据: portugal - liga-nos - 2021-to-2022\n",
      "加载数据: portugal - liga-nos - 2022-to-2023\n",
      "加载数据: portugal - liga-nos - 2023-to-2024\n",
      "加载数据: italy - serie-b - 2013-to-2014\n",
      "加载数据: italy - serie-b - 2014-to-2015\n",
      "加载数据: italy - serie-b - 2015-to-2016\n",
      "加载数据: italy - serie-b - 2016-to-2017\n",
      "加载数据: italy - serie-b - 2017-to-2018\n",
      "加载数据: italy - serie-b - 2018-to-2019\n",
      "加载数据: italy - serie-b - 2020-to-2021\n",
      "加载数据: italy - serie-b - 2021-to-2022\n",
      "加载数据: italy - serie-b - 2022-to-2023\n",
      "加载数据: italy - serie-b - 2023-to-2024\n",
      "加载数据: germany - 2-bundesliga - 2013-to-2014\n",
      "加载数据: germany - 2-bundesliga - 2014-to-2015\n",
      "加载数据: germany - 2-bundesliga - 2015-to-2016\n",
      "加载数据: germany - 2-bundesliga - 2016-to-2017\n",
      "加载数据: germany - 2-bundesliga - 2017-to-2018\n",
      "加载数据: germany - 2-bundesliga - 2018-to-2019\n",
      "加载数据: germany - 2-bundesliga - 2020-to-2021\n",
      "加载数据: germany - 2-bundesliga - 2021-to-2022\n",
      "加载数据: germany - 2-bundesliga - 2022-to-2023\n",
      "加载数据: germany - 2-bundesliga - 2023-to-2024\n",
      "\n",
      "===== 运行网格搜索 =====\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.001, lambda_supervision=0.001 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.001, lambda_supervision=0.001 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.001, lambda_supervision=0.005 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.001, lambda_supervision=0.005 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.001, lambda_supervision=0.01 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.001, lambda_supervision=0.01 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.001, lambda_supervision=0.5 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.001, lambda_supervision=0.5 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.001, lambda_supervision=1.0 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.001, lambda_supervision=1.0 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.005, lambda_supervision=0.001 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.005, lambda_supervision=0.001 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.005, lambda_supervision=0.005 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.005, lambda_supervision=0.005 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.005, lambda_supervision=0.01 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.005, lambda_supervision=0.01 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.005, lambda_supervision=0.5 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.005, lambda_supervision=0.5 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.005, lambda_supervision=1.0 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.005, lambda_supervision=1.0 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.01, lambda_supervision=0.001 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.01, lambda_supervision=0.001 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.01, lambda_supervision=0.005 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.01, lambda_supervision=0.005 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.01, lambda_supervision=0.01 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.01, lambda_supervision=0.01 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.01, lambda_supervision=0.5 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.01, lambda_supervision=0.5 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.01, lambda_supervision=1.0 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.01, lambda_supervision=1.0 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.5, lambda_supervision=0.001 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.5, lambda_supervision=0.001 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.5, lambda_supervision=0.005 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.5, lambda_supervision=0.005 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.5, lambda_supervision=0.01 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.5, lambda_supervision=0.01 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.5, lambda_supervision=0.5 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.5, lambda_supervision=0.5 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=0.5, lambda_supervision=1.0 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=0.5, lambda_supervision=1.0 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=1.0, lambda_supervision=0.001 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=1.0, lambda_supervision=0.001 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=1.0, lambda_supervision=0.005 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=1.0, lambda_supervision=0.005 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=1.0, lambda_supervision=0.01 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=1.0, lambda_supervision=0.01 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=1.0, lambda_supervision=0.5 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=1.0, lambda_supervision=0.5 的平均测试损失 = 0.1721\n",
      "\n",
      "===== 网格搜索: lambda_defense=1.0, lambda_supervision=1.0 =====\n",
      "\n",
      "===== 第 1/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6275\n",
      "迭代 10000/50000, 损失 = 0.2893, 学习率 = 0.000956, rank_scale = 6.3874\n",
      "迭代 15000/50000, 损失 = 0.2311, 学习率 = 0.000935, rank_scale = 9.8097\n",
      "迭代 20000/50000, 损失 = 0.1949, 学习率 = 0.000915, rank_scale = 13.5551\n",
      "迭代 25000/50000, 损失 = 0.1697, 学习率 = 0.000894, rank_scale = 17.4305\n",
      "迭代 30000/50000, 损失 = 0.1511, 学习率 = 0.000875, rank_scale = 21.3477\n",
      "迭代 35000/50000, 损失 = 0.1365, 学习率 = 0.000855, rank_scale = 25.2638\n",
      "迭代 40000/50000, 损失 = 0.1248, 学习率 = 0.000837, rank_scale = 29.1523\n",
      "迭代 45000/50000, 损失 = 0.1152, 学习率 = 0.000818, rank_scale = 32.9971\n",
      "迭代 50000/50000, 损失 = 0.1072, 学习率 = 0.000800, rank_scale = 36.7871\n",
      "=> 训练完成, 最佳损失=0.1072, 最佳 rank_scale=36.7863\n",
      "第 1 次拆分: 训练损失 = 0.1072, 测试损失 = 0.1642\n",
      "\n",
      "===== 第 2/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4099, 学习率 = 0.000978, rank_scale = 3.6289\n",
      "迭代 10000/50000, 损失 = 0.2884, 学习率 = 0.000956, rank_scale = 6.3920\n",
      "迭代 15000/50000, 损失 = 0.2299, 学习率 = 0.000935, rank_scale = 9.8150\n",
      "迭代 20000/50000, 损失 = 0.1930, 学习率 = 0.000915, rank_scale = 13.5579\n",
      "迭代 25000/50000, 损失 = 0.1676, 学习率 = 0.000894, rank_scale = 17.4324\n",
      "迭代 30000/50000, 损失 = 0.1491, 学习率 = 0.000875, rank_scale = 21.3496\n",
      "迭代 35000/50000, 损失 = 0.1347, 学习率 = 0.000855, rank_scale = 25.2653\n",
      "迭代 40000/50000, 损失 = 0.1231, 学习率 = 0.000837, rank_scale = 29.1524\n",
      "迭代 45000/50000, 损失 = 0.1136, 学习率 = 0.000818, rank_scale = 32.9941\n",
      "迭代 50000/50000, 损失 = 0.1056, 学习率 = 0.000800, rank_scale = 36.7819\n",
      "=> 训练完成, 最佳损失=0.1056, 最佳 rank_scale=36.7812\n",
      "第 2 次拆分: 训练损失 = 0.1056, 测试损失 = 0.1849\n",
      "\n",
      "===== 第 3/3 次拆分 =====\n",
      "迭代 5000/50000, 损失 = 0.4096, 学习率 = 0.000978, rank_scale = 3.6269\n",
      "迭代 10000/50000, 损失 = 0.2892, 学习率 = 0.000956, rank_scale = 6.3877\n",
      "迭代 15000/50000, 损失 = 0.2306, 学习率 = 0.000935, rank_scale = 9.8085\n",
      "迭代 20000/50000, 损失 = 0.1946, 学习率 = 0.000915, rank_scale = 13.5535\n",
      "迭代 25000/50000, 损失 = 0.1693, 学习率 = 0.000894, rank_scale = 17.4304\n",
      "迭代 30000/50000, 损失 = 0.1505, 学习率 = 0.000875, rank_scale = 21.3481\n",
      "迭代 35000/50000, 损失 = 0.1361, 学习率 = 0.000855, rank_scale = 25.2640\n",
      "迭代 40000/50000, 损失 = 0.1245, 学习率 = 0.000837, rank_scale = 29.1518\n",
      "迭代 45000/50000, 损失 = 0.1151, 学习率 = 0.000818, rank_scale = 32.9951\n",
      "迭代 50000/50000, 损失 = 0.1071, 学习率 = 0.000800, rank_scale = 36.7839\n",
      "=> 训练完成, 最佳损失=0.1071, 最佳 rank_scale=36.7839\n",
      "第 3 次拆分: 训练损失 = 0.1071, 测试损失 = 0.1671\n",
      "lambda_defense=1.0, lambda_supervision=1.0 的平均测试损失 = 0.1721\n",
      "\n",
      "最佳超参数: lambda_defense=0.001, lambda_supervision=0.001, 最佳测试损失=0.1721\n",
      "\n",
      "===== 使用最佳超参数训练最终模型 =====\n",
      "迭代 5000/50000, 损失 = 0.4211, 学习率 = 0.000978, rank_scale = 3.6224\n",
      "迭代 10000/50000, 损失 = 0.3004, 学习率 = 0.000956, rank_scale = 6.3734\n",
      "迭代 15000/50000, 损失 = 0.2415, 学习率 = 0.000935, rank_scale = 9.7879\n",
      "迭代 20000/50000, 损失 = 0.2045, 学习率 = 0.000915, rank_scale = 13.5274\n",
      "迭代 25000/50000, 损失 = 0.1785, 学习率 = 0.000894, rank_scale = 17.3997\n",
      "迭代 30000/50000, 损失 = 0.1590, 学习率 = 0.000875, rank_scale = 21.3151\n",
      "迭代 35000/50000, 损失 = 0.1439, 学习率 = 0.000855, rank_scale = 25.2297\n",
      "迭代 40000/50000, 损失 = 0.1318, 学习率 = 0.000837, rank_scale = 29.1160\n",
      "迭代 45000/50000, 损失 = 0.1217, 学习率 = 0.000818, rank_scale = 32.9576\n",
      "迭代 50000/50000, 损失 = 0.1133, 学习率 = 0.000800, rank_scale = 36.7454\n",
      "=> 训练完成, 最佳损失=0.1133, 最佳 rank_scale=36.7454\n",
      "最终训练损失: 0.1133, 最佳 rank_scale: 36.7454\n",
      "\n",
      "===== 按联赛可视化球队演变 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存 premier-league 的静态演变图 -> /Users/peixuanma/Downloads/Output_Graphs/premier-league_evolution_static.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存 bundesliga 的静态演变图 -> /Users/peixuanma/Downloads/Output_Graphs/bundesliga_evolution_static.png\n",
      "保存 la-liga 的静态演变图 -> /Users/peixuanma/Downloads/Output_Graphs/la-liga_evolution_static.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存 ligue-1 的静态演变图 -> /Users/peixuanma/Downloads/Output_Graphs/ligue-1_evolution_static.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存 serie-a 的静态演变图 -> /Users/peixuanma/Downloads/Output_Graphs/serie-a_evolution_static.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存 eredivisie 的静态演变图 -> /Users/peixuanma/Downloads/Output_Graphs/eredivisie_evolution_static.png\n",
      "ligapro 中没有球队连续出现在所有赛季，使用所有球队。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存 ligapro 的静态演变图 -> /Users/peixuanma/Downloads/Output_Graphs/ligapro_evolution_static.png\n",
      "保存 superliga 的静态演变图 -> /Users/peixuanma/Downloads/Output_Graphs/superliga_evolution_static.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存 championship 的静态演变图 -> /Users/peixuanma/Downloads/Output_Graphs/championship_evolution_static.png\n",
      "保存 liga-nos 的静态演变图 -> /Users/peixuanma/Downloads/Output_Graphs/liga-nos_evolution_static.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存 serie-b 的静态演变图 -> /Users/peixuanma/Downloads/Output_Graphs/serie-b_evolution_static.png\n",
      "保存 2-bundesliga 的静态演变图 -> /Users/peixuanma/Downloads/Output_Graphs/2-bundesliga_evolution_static.png\n",
      "\n",
      "完成！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:607: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38450 (\\N{CJK UNIFIED IDEOGRAPH-9632}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 23432 (\\N{CJK UNIFIED IDEOGRAPH-5B88}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 29699 (\\N{CJK UNIFIED IDEOGRAPH-7403}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 38431 (\\N{CJK UNIFIED IDEOGRAPH-961F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 28436 (\\N{CJK UNIFIED IDEOGRAPH-6F14}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n",
      "/var/folders/m9/4339fc7572b6ls3dzsvjfg000000gn/T/ipykernel_82726/1053278601.py:609: UserWarning: Glyph 25915 (\\N{CJK UNIFIED IDEOGRAPH-653B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(filename, dpi=150)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8f2a00d68ec29598"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
